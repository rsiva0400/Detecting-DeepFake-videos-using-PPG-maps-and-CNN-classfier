{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traing data\n",
    "real_images_path = 'out_real_ryv'\n",
    "fake_images_path = 'out_fake_ryv'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load real images\n",
    "for filename in os.listdir(real_images_path)[:2433]:\n",
    "    if filename.endswith(\".png\"):  \n",
    "        img = cv2.imread(os.path.join(real_images_path, filename))\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "        labels.append(1)  \n",
    "\n",
    "# Load fake images\n",
    "for filename in os.listdir(fake_images_path)[:2413]:\n",
    "    if filename.endswith(\".png\"):  \n",
    "        img = cv2.imread(os.path.join(fake_images_path, filename))\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "        labels.append(0)  \n",
    "\n",
    "train_images = np.array(images)\n",
    "train_labels = np.array(labels)\n",
    "\n",
    "temp = list(zip(train_images, train_labels))\n",
    "random.shuffle(temp)\n",
    "res1, res2 = zip(*temp)\n",
    "res1, res2 = list(res1), list(res2)\n",
    "\n",
    "X_train = np.array(res1) / 255.0\n",
    "y_train= np.array(res2)\n",
    "\n",
    "# temp=[]\n",
    "# res1=[]\n",
    "# res2=[]\n",
    "# train_images=[]\n",
    "# train_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4846, 128, 32, 3) (4846,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "real_images_path = 'out_real_ryv'\n",
    "fake_images_path = 'out_fake_ryv'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load real images\n",
    "for filename in os.listdir(real_images_path)[2433:]:\n",
    "    if filename.endswith(\".png\"):  \n",
    "        img = cv2.imread(os.path.join(real_images_path, filename))\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "        labels.append(1)  \n",
    "\n",
    "# Load fake images\n",
    "for filename in os.listdir(fake_images_path)[2413:]:\n",
    "    if filename.endswith(\".png\"):  \n",
    "        img = cv2.imread(os.path.join(fake_images_path, filename))\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "        labels.append(0)  \n",
    "\n",
    "test_images = np.array(images)\n",
    "test_labels = np.array(labels)\n",
    "\n",
    "X_test= np.array(test_images)/255.0\n",
    "y_test= test_labels\n",
    "\n",
    "# test_images=[]\n",
    "# test_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981, 128, 32, 3) (1981,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(128, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.005)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.005)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=l2(0.005)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(55, activation='relu', kernel_regularizer=l2(0.005)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(60, activation='relu', kernel_regularizer=l2(0.005)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 126, 30, 16)       448       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 63, 15, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 63, 15, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 61, 13, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 30, 6, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 30, 6, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 4, 32)         9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 2, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 14, 2, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 896)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                44850     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 55)                2805      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 55)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 60)                3360      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,732\n",
      "Trainable params: 65,572\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "custom_optimizer = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=custom_optimizer, loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStartTrainingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, loss_threshold=0.3, accuracy_threshold=0.95):\n",
    "        super(EarlyStartTrainingCallback, self).__init__()\n",
    "        self.loss_threshold = loss_threshold\n",
    "        self.accuracy_threshold = accuracy_threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        \n",
    "        val_loss = logs.get('val_loss')\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if val_loss is not None and val_acc is not None and val_loss < self.loss_threshold and val_acc > self.accuracy_threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Create the callback\n",
    "early_start_callback = EarlyStartTrainingCallback(loss_threshold=0.25, accuracy_threshold=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "152/152 [==============================] - 12s 71ms/step - loss: 1.7368 - accuracy: 0.5809 - val_loss: 1.5235 - val_accuracy: 0.5411\n",
      "Epoch 2/80\n",
      "152/152 [==============================] - 10s 64ms/step - loss: 1.2943 - accuracy: 0.6830 - val_loss: 1.4785 - val_accuracy: 0.4972\n",
      "Epoch 3/80\n",
      "152/152 [==============================] - 10s 64ms/step - loss: 0.9538 - accuracy: 0.7639 - val_loss: 1.2126 - val_accuracy: 0.6371\n",
      "Epoch 4/80\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.7070 - accuracy: 0.8395 - val_loss: 0.7698 - val_accuracy: 0.7713\n",
      "Epoch 5/80\n",
      "152/152 [==============================] - 10s 67ms/step - loss: 0.5303 - accuracy: 0.8898 - val_loss: 0.5275 - val_accuracy: 0.8804\n",
      "Epoch 6/80\n",
      "152/152 [==============================] - 11s 71ms/step - loss: 0.4490 - accuracy: 0.9067 - val_loss: 0.4351 - val_accuracy: 0.9011\n",
      "Epoch 7/80\n",
      "152/152 [==============================] - 11s 73ms/step - loss: 0.3706 - accuracy: 0.9272 - val_loss: 0.4619 - val_accuracy: 0.8672\n",
      "Epoch 8/80\n",
      "152/152 [==============================] - 11s 73ms/step - loss: 0.3361 - accuracy: 0.9327 - val_loss: 0.3236 - val_accuracy: 0.9298\n",
      "Epoch 9/80\n",
      "152/152 [==============================] - 11s 73ms/step - loss: 0.3144 - accuracy: 0.9319 - val_loss: 0.3779 - val_accuracy: 0.8955\n",
      "Epoch 10/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2811 - accuracy: 0.9449 - val_loss: 1.4541 - val_accuracy: 0.5588\n",
      "Epoch 11/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2753 - accuracy: 0.9449 - val_loss: 0.3873 - val_accuracy: 0.9011\n",
      "Epoch 12/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2564 - accuracy: 0.9567 - val_loss: 0.3224 - val_accuracy: 0.9223\n",
      "Epoch 13/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2554 - accuracy: 0.9523 - val_loss: 0.2795 - val_accuracy: 0.9425\n",
      "Epoch 14/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2447 - accuracy: 0.9583 - val_loss: 0.2892 - val_accuracy: 0.9374\n",
      "Epoch 15/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2214 - accuracy: 0.9635 - val_loss: 0.8559 - val_accuracy: 0.7491\n",
      "Epoch 16/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2242 - accuracy: 0.9624 - val_loss: 0.3589 - val_accuracy: 0.9157\n",
      "Epoch 17/80\n",
      "152/152 [==============================] - 13s 87ms/step - loss: 0.2255 - accuracy: 0.9633 - val_loss: 0.4354 - val_accuracy: 0.8733\n",
      "Epoch 18/80\n",
      "152/152 [==============================] - 13s 87ms/step - loss: 0.2223 - accuracy: 0.9645 - val_loss: 0.2942 - val_accuracy: 0.9263\n",
      "Epoch 19/80\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.2335 - accuracy: 0.9593 - val_loss: 0.6627 - val_accuracy: 0.8127\n",
      "Epoch 20/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2183 - accuracy: 0.9672 - val_loss: 0.2729 - val_accuracy: 0.9399\n",
      "Epoch 21/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2004 - accuracy: 0.9723 - val_loss: 0.7037 - val_accuracy: 0.7895\n",
      "Epoch 22/80\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.1958 - accuracy: 0.9721 - val_loss: 0.2912 - val_accuracy: 0.9308\n",
      "Epoch 23/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1996 - accuracy: 0.9711 - val_loss: 0.8590 - val_accuracy: 0.7320\n",
      "Epoch 24/80\n",
      "152/152 [==============================] - 11s 73ms/step - loss: 0.2100 - accuracy: 0.9674 - val_loss: 0.5360 - val_accuracy: 0.8556\n",
      "Epoch 25/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2073 - accuracy: 0.9693 - val_loss: 0.4078 - val_accuracy: 0.8829\n",
      "Epoch 26/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1985 - accuracy: 0.9734 - val_loss: 0.3330 - val_accuracy: 0.9268\n",
      "Epoch 27/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2210 - accuracy: 0.9626 - val_loss: 0.2970 - val_accuracy: 0.9243\n",
      "Epoch 28/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.2003 - accuracy: 0.9736 - val_loss: 0.2767 - val_accuracy: 0.9409\n",
      "Epoch 29/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.2089 - accuracy: 0.9711 - val_loss: 0.3000 - val_accuracy: 0.9303\n",
      "Epoch 30/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1809 - accuracy: 0.9777 - val_loss: 0.3163 - val_accuracy: 0.9243\n",
      "Epoch 31/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1897 - accuracy: 0.9759 - val_loss: 0.3241 - val_accuracy: 0.9308\n",
      "Epoch 32/80\n",
      "152/152 [==============================] - 12s 77ms/step - loss: 0.1799 - accuracy: 0.9806 - val_loss: 0.3289 - val_accuracy: 0.9319\n",
      "Epoch 33/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1847 - accuracy: 0.9748 - val_loss: 0.2927 - val_accuracy: 0.9389\n",
      "Epoch 34/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1837 - accuracy: 0.9767 - val_loss: 0.6258 - val_accuracy: 0.8198\n",
      "Epoch 35/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1892 - accuracy: 0.9750 - val_loss: 0.2610 - val_accuracy: 0.9470\n",
      "Epoch 36/80\n",
      "152/152 [==============================] - 13s 85ms/step - loss: 0.1878 - accuracy: 0.9744 - val_loss: 0.3074 - val_accuracy: 0.9359\n",
      "Epoch 37/80\n",
      "152/152 [==============================] - 12s 79ms/step - loss: 0.1756 - accuracy: 0.9798 - val_loss: 0.3422 - val_accuracy: 0.9112\n",
      "Epoch 38/80\n",
      "152/152 [==============================] - 11s 76ms/step - loss: 0.1841 - accuracy: 0.9765 - val_loss: 0.3159 - val_accuracy: 0.9283\n",
      "Epoch 39/80\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.1730 - accuracy: 0.9800 - val_loss: 0.2622 - val_accuracy: 0.9510\n",
      "Epoch 40/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1782 - accuracy: 0.9779 - val_loss: 0.2641 - val_accuracy: 0.9430\n",
      "Epoch 41/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1723 - accuracy: 0.9794 - val_loss: 0.2518 - val_accuracy: 0.9470\n",
      "Epoch 42/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1739 - accuracy: 0.9796 - val_loss: 0.2860 - val_accuracy: 0.9344\n",
      "Epoch 43/80\n",
      "152/152 [==============================] - 12s 77ms/step - loss: 0.2003 - accuracy: 0.9690 - val_loss: 0.2717 - val_accuracy: 0.9505\n",
      "Epoch 44/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1927 - accuracy: 0.9754 - val_loss: 0.2504 - val_accuracy: 0.9541\n",
      "Epoch 45/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1739 - accuracy: 0.9767 - val_loss: 0.8218 - val_accuracy: 0.7769\n",
      "Epoch 46/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1764 - accuracy: 0.9767 - val_loss: 0.3258 - val_accuracy: 0.9324\n",
      "Epoch 47/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1915 - accuracy: 0.9730 - val_loss: 0.3750 - val_accuracy: 0.9076\n",
      "Epoch 48/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1739 - accuracy: 0.9761 - val_loss: 0.3037 - val_accuracy: 0.9445\n",
      "Epoch 49/80\n",
      "152/152 [==============================] - 11s 76ms/step - loss: 0.1630 - accuracy: 0.9818 - val_loss: 0.5619 - val_accuracy: 0.8894\n",
      "Epoch 50/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1675 - accuracy: 0.9812 - val_loss: 0.3554 - val_accuracy: 0.9172\n",
      "Epoch 51/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1701 - accuracy: 0.9823 - val_loss: 0.2718 - val_accuracy: 0.9435\n",
      "Epoch 52/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1655 - accuracy: 0.9808 - val_loss: 0.7088 - val_accuracy: 0.8248\n",
      "Epoch 53/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1577 - accuracy: 0.9814 - val_loss: 0.2766 - val_accuracy: 0.9384\n",
      "Epoch 54/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1481 - accuracy: 0.9841 - val_loss: 0.3098 - val_accuracy: 0.9409\n",
      "Epoch 55/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1609 - accuracy: 0.9785 - val_loss: 1.4643 - val_accuracy: 0.6371\n",
      "Epoch 56/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1732 - accuracy: 0.9759 - val_loss: 0.3512 - val_accuracy: 0.9127\n",
      "Epoch 57/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1845 - accuracy: 0.9765 - val_loss: 0.6248 - val_accuracy: 0.7799\n",
      "Epoch 58/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1550 - accuracy: 0.9833 - val_loss: 0.2919 - val_accuracy: 0.9445\n",
      "Epoch 59/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1569 - accuracy: 0.9833 - val_loss: 0.3647 - val_accuracy: 0.9308\n",
      "Epoch 60/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1620 - accuracy: 0.9800 - val_loss: 1.4727 - val_accuracy: 0.6032\n",
      "Epoch 61/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1574 - accuracy: 0.9796 - val_loss: 0.6592 - val_accuracy: 0.8299\n",
      "Epoch 62/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1533 - accuracy: 0.9839 - val_loss: 0.2919 - val_accuracy: 0.9389\n",
      "Epoch 63/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1762 - accuracy: 0.9748 - val_loss: 0.2746 - val_accuracy: 0.9520\n",
      "Epoch 64/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1502 - accuracy: 0.9851 - val_loss: 0.2836 - val_accuracy: 0.9470\n",
      "Epoch 65/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1593 - accuracy: 0.9800 - val_loss: 0.2555 - val_accuracy: 0.9571\n",
      "Epoch 66/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1513 - accuracy: 0.9829 - val_loss: 0.4064 - val_accuracy: 0.8819\n",
      "Epoch 67/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1605 - accuracy: 0.9806 - val_loss: 0.2817 - val_accuracy: 0.9379\n",
      "Epoch 68/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1463 - accuracy: 0.9841 - val_loss: 0.2541 - val_accuracy: 0.9505\n",
      "Epoch 69/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1446 - accuracy: 0.9853 - val_loss: 0.2372 - val_accuracy: 0.9531\n",
      "Epoch 70/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1567 - accuracy: 0.9796 - val_loss: 0.2651 - val_accuracy: 0.9445\n",
      "Epoch 71/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1550 - accuracy: 0.9794 - val_loss: 0.2844 - val_accuracy: 0.9389\n",
      "Epoch 72/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1589 - accuracy: 0.9818 - val_loss: 0.2504 - val_accuracy: 0.9495\n",
      "Epoch 73/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1566 - accuracy: 0.9800 - val_loss: 0.3659 - val_accuracy: 0.9319\n",
      "Epoch 74/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1410 - accuracy: 0.9887 - val_loss: 0.2649 - val_accuracy: 0.9485\n",
      "Epoch 75/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1410 - accuracy: 0.9866 - val_loss: 0.3380 - val_accuracy: 0.9147\n",
      "Epoch 76/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1619 - accuracy: 0.9765 - val_loss: 0.2449 - val_accuracy: 0.9475\n",
      "Epoch 77/80\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.1603 - accuracy: 0.9808 - val_loss: 0.5308 - val_accuracy: 0.8405\n",
      "Epoch 78/80\n",
      "152/152 [==============================] - 11s 76ms/step - loss: 0.1489 - accuracy: 0.9833 - val_loss: 0.2487 - val_accuracy: 0.9551\n",
      "Epoch 79/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1412 - accuracy: 0.9853 - val_loss: 0.4483 - val_accuracy: 0.9056\n",
      "Epoch 80/80\n",
      "152/152 [==============================] - 11s 75ms/step - loss: 0.1438 - accuracy: 0.9827 - val_loss: 0.2444 - val_accuracy: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f52fc9430>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),callbacks=[early_start_callback], epochs=80, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model.save('model_cnn_ppgryv1_train_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # Define the CNN model\n",
    "# model_dscnn = Sequential()\n",
    "\n",
    "# # Depth-wise separable convolution layer\n",
    "# model_dscnn.add(layers.DepthwiseConv2D(3, activation='relu', input_shape=(128,32, 1)))\n",
    "# model_dscnn.add(layers.BatchNormalization())\n",
    "# model_dscnn.add(layers.SeparableConv2D(32, (3, 3), activation='relu'))\n",
    "# model_dscnn.add(layers.BatchNormalization())\n",
    "# model_dscnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Another depth-wise separable convolution layer\n",
    "# model_dscnn.add(layers.SeparableConv2D(64, (3, 3), activation='relu'))\n",
    "# model_dscnn.add(layers.BatchNormalization())\n",
    "# model_dscnn.add(layers.SeparableConv2D(64, (3, 3), activation='relu'))\n",
    "# model_dscnn.add(layers.BatchNormalization())\n",
    "# model_dscnn.add(layers.MaxPooling2D((2, 2)))\n",
    "# model_dscnn.add(Flatten())\n",
    "# model_dscnn.add(layers.Dense(128, activation='relu'))\n",
    "# model_dscnn.add(layers.Dropout(0.5))\n",
    "# model_dscnn.add(layers.Dense(1, activation='sigmoid'))  # 2 classes for binary classification\n",
    "\n",
    "# # Compile the model\n",
    "# model_dscnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Print the model summary\n",
    "# model_dscnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 20ms/step - loss: 0.2444 - accuracy: 0.9551\n",
      "Test loss: 0.24435880780220032\n",
      "Test accuracy: 0.9550731778144836\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.999983], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "t1=cv2.imread('out_real_ryv/702_1.png')\n",
    "t1=t1/255.0\n",
    "batch_of_images = np.array([t1]*32)\n",
    "predictions=model.predict(batch_of_images)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=[]\n",
    "original_labels=[]\n",
    "for i in range(300):\n",
    "    original_labels.append(0) #fake\n",
    "for i in range(300):\n",
    "    original_labels.append(1) #real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fake={}\n",
    "testing_videos_fake=os.listdir('out_fake_ryv')[2416:]\n",
    "for i in testing_videos_fake:\n",
    "    d_fake[i[:-6]]=[]\n",
    "for i in testing_videos_fake:\n",
    "    img_test=cv2.imread(f'E:/FF++/out_fake_ryv/{i}')\n",
    "    d_fake[i[:-6]].append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_real={}\n",
    "testing_videos_fake=os.listdir('out_real_ryv')[2436:]\n",
    "for i in testing_videos_fake:\n",
    "    d_real[i[:-6]]=[]\n",
    "for i in testing_videos_fake:\n",
    "    img_test=cv2.imread(f'E:/FF++/out_real_ryv/{i}')\n",
    "    d_real[i[:-6]].append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_real), len(d_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 1]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[1, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1]\n",
      "[0, 1]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[1, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[1, 0, 0, 1]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[1, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[1, 0, 0]\n",
      "[1, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[1, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[1, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 1]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[1, 1, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i, j in d_fake.items():\n",
    "    segment_predictions=[]\n",
    "    for k in j:\n",
    "        k=k/255.0\n",
    "        batch_of_images = np.array([k] * 32)\n",
    "        predictions=model.predict([batch_of_images])\n",
    "        if(predictions[0][0]>0.5):\n",
    "            pc=1\n",
    "        else:\n",
    "            pc=0\n",
    "        segment_predictions.append(pc)\n",
    "    print(segment_predictions)\n",
    "    if(Counter(segment_predictions)[0]>=Counter(segment_predictions)[1]):\n",
    "        vid_prediction=0\n",
    "    else:\n",
    "        vid_prediction=1\n",
    "    predicted_labels.append(vid_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[0, 0]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 0]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 0, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 0, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 1, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[0, 0, 1]\n",
      "[1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 0]\n",
      "[0, 0]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 0]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 0]\n",
      "[1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0]\n",
      "[1, 1, 1]\n",
      "[1, 1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i, j in d_real.items():\n",
    "    segment_predictions=[]\n",
    "    for k in j:\n",
    "        k=k/255.0\n",
    "        batch_of_images = np.array([k] * 32)\n",
    "        predictions=model.predict([batch_of_images])\n",
    "        if(predictions[0][0]>0.5):\n",
    "            pc=1\n",
    "        else:\n",
    "            pc=0\n",
    "        segment_predictions.append(pc)\n",
    "    print(segment_predictions)\n",
    "    if(Counter(segment_predictions)[0]>=Counter(segment_predictions)[1]):\n",
    "        vid_prediction=0\n",
    "    else:\n",
    "        vid_prediction=1\n",
    "    predicted_labels.append(vid_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_labels), len(original_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(predicted_labels,original_labels):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293,   7],\n",
       "       [ 15, 285]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "confusion_matrix(original_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy   : 0.9633333333333334\n",
      "Precision : 0.976027397260274\n",
      "Recall    : 0.95\n",
      "F1-score  : 0.9628378378378378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(original_labels, predicted_labels)\n",
    "print(\"Accuracy   :\", accuracy)\n",
    "precision = precision_score(original_labels, predicted_labels)\n",
    "print(\"Precision :\", precision)\n",
    "recall = recall_score(original_labels, predicted_labels)\n",
    "print(\"Recall    :\", recall)\n",
    "F1_score = f1_score(original_labels, predicted_labels)\n",
    "print(\"F1-score  :\", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from sklearn import preprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppgs(vid_path):\n",
    "    ppg_maps=[]\n",
    "    # Define the input video file path\n",
    "    video_path = vid_path\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the frames per second (fps) and total frame count\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Set the desired number of frames per segment\n",
    "    frames_per_segment = 128  # Set to 128 frames per segment\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks/shape_predictor_68_face_landmarks (1).dat\")  # You need to download this file\n",
    "    # detector.set_min_detection_confidence(0.5)\n",
    "    # Initialize variables to keep track of segment number and frames\n",
    "    segment_number = 1\n",
    "    frame_count = 0\n",
    "    ppgmap=np.empty([128,32,3])\n",
    "    ind=0\n",
    "\n",
    "    while True:\n",
    "        #print(\"hi\")\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame=cv2.resize(frame,(854,480))\n",
    "        \n",
    "        # Convert the frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if(len(detector(gray))==0):\n",
    "            continue\n",
    "\n",
    "        face = detector(gray)[0]\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Extract the coordinates of the nose (e.g., landmark point 30)\n",
    "        nose_x = landmarks.part(30).x\n",
    "        nose_y = landmarks.part(30).y\n",
    "\n",
    "        # Define the ROI around the nose\n",
    "        roi_size_width = 64\n",
    "        roi_size_height = 32\n",
    "        roi_x = nose_x - roi_size_width//2\n",
    "        roi_y = nose_y - roi_size_height//2\n",
    "\n",
    "        # Ensure ROI coordinates are within bounds\n",
    "        roi_x = max(0, roi_x)\n",
    "        roi_y = max(0, roi_y)\n",
    "        roi_x_end = min(frame.shape[1], roi_x + roi_size_width)\n",
    "        roi_y_end = min(frame.shape[0], roi_y + roi_size_height)\n",
    "\n",
    "        # Extract the ROI\n",
    "        roi = frame[roi_y:roi_y_end, roi_x:roi_x_end]\n",
    "        \n",
    "        # Calculate subregion size\n",
    "        subregion_width = roi_size_width // 8  # 8 subregions horizontally\n",
    "        subregion_height = roi_size_height // 4  # 4 subregions vertically\n",
    "\n",
    "        subregions_r=np.zeros(32)\n",
    "        subregions_y=np.zeros(32)\n",
    "        subregions_v=np.zeros(32)\n",
    "        k=0\n",
    "        for i in range(4):\n",
    "            for j in range(8):\n",
    "                left = j * subregion_width\n",
    "                upper = i * subregion_height\n",
    "                right = (j + 1) * subregion_width\n",
    "                lower = (i + 1) * subregion_height\n",
    "                subregion=roi[upper:lower, left:right]\n",
    "\n",
    "                roi_ycbcr = cv2.cvtColor(subregion, cv2.COLOR_BGR2YCrCb)\n",
    "                roi_hsv = cv2.cvtColor(subregion, cv2.COLOR_BGR2HSV)\n",
    "                \n",
    "                y_comp = np.mean(roi_ycbcr[:, :, 0])  \n",
    "                v_comp = np.mean(roi_hsv[:, :, 2])  \n",
    "                rv=np.mean(subregion[:,:,0])\n",
    "                \n",
    "                subregions_r[k]=rv\n",
    "                subregions_y[k]=y_comp\n",
    "                subregions_v[k]=v_comp\n",
    "                \n",
    "                k+=1\n",
    "                \n",
    "        ppgmap[ind,:,0]=subregions_r\n",
    "        ppgmap[ind,:,1]=subregions_y\n",
    "        ppgmap[ind,:,2]=subregions_v\n",
    "        #print(ppgmap[ind])\n",
    "        ind+=1\n",
    "        frame_count += 1\n",
    "        #curr_seg.append(frame)\n",
    "        #print(ppgmap[ind])\n",
    "        if frame_count == frames_per_segment:\n",
    "            min_values = np.min(ppgmap, axis=(0, 1))\n",
    "            max_values = np.max(ppgmap, axis=(0, 1))\n",
    "            scaled_data = ((ppgmap - min_values) / (max_values - min_values) * 255.0).astype(np.uint8)\n",
    "            ppg_maps.append(scaled_data)\n",
    "            segment_number += 1\n",
    "            ppgmap=np.empty([128,32,3])\n",
    "            ind=0\n",
    "            frame_count = 0\n",
    "    cap.release()\n",
    "    return ppg_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98685056 0.32960775 [1, 0]\n",
      "Prediction from our model:  0\n"
     ]
    }
   ],
   "source": [
    "ppgs_for_video=get_ppgs(r\"C:\\Users\\hites\\Downloads\\deepfake-detection-challenge\\train_sample_videos\\errocgcham.mp4\")\n",
    "segment_predictions=[]\n",
    "for k in ppgs_for_video:\n",
    "    k=k/255.0\n",
    "    batch_of_images = np.array([k] * 32)\n",
    "    predictions=model.predict([batch_of_images])\n",
    "    print(predictions[0][0],end=\" \")\n",
    "    if(predictions[0][0]>0.5):\n",
    "        pc=1\n",
    "    else:\n",
    "        pc=0\n",
    "    segment_predictions.append(pc)\n",
    "print(segment_predictions)\n",
    "if(Counter(segment_predictions)[0]>=Counter(segment_predictions)[1]):\n",
    "    vid_prediction=0\n",
    "else:\n",
    "    vid_prediction=1\n",
    "\n",
    "print(\"Prediction from our model: \",vid_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
